from pytubefix import YouTube
import pyaudio
import wave
import sys
import os
from raw_data.raw_data import *
from raw_data.constants import *
import crepe
from scipy.io import wavfile
import matplotlib.pyplot as plt
import numpy as np
import sounddevice as sd
import time
from IPython.display import clear_output





# -*- coding: utf-8 -*-
'''recorder.py
Provides WAV recording functionality via two approaches:

Blocking mode (record for a set duration):
>>> rec = Recorder(channels=2)
>>> with rec.open('blocking.wav', 'wb') as recfile:
...     recfile.record(duration=5.0)

Non-blocking mode (start and stop recording):
>>> rec = Recorder(channels=2)
>>> with rec.open('nonblocking.wav', 'wb') as recfile2:
...     recfile2.start_recording()
...     time.sleep(5.0)
...     recfile2.stop_recording()
'''
frames = []
class Recorder(object):
    '''A recorder class for recording audio to a WAV file.
    Records in mono by default.
    '''

    def __init__(self, channels=1, rate=44100, frames_per_buffer=1024):
        self.channels = channels
        self.rate = rate
        self.frames_per_buffer = frames_per_buffer

    def open(self, fname, mode='wb'):
        return RecordingFile(fname, mode, self.channels, self.rate,
                            self.frames_per_buffer)

class RecordingFile(object):
    def __init__(self, fname, mode, channels, 
                rate, frames_per_buffer):
        self.fname = fname
        self.mode = mode
        self.channels = channels
        self.rate = rate
        self.frames_per_buffer = frames_per_buffer
        self._pa = pyaudio.PyAudio()
        self.wavefile = self._prepare_file(self.fname, self.mode)
        self._stream = None

    def __enter__(self):
        return self

    def __exit__(self, exception, value, traceback):
        self.close()

    def record(self, duration):
        # Use a stream with no callback function in blocking mode
        self._stream = self._pa.open(format=pyaudio.paInt16,
                                        channels=self.channels,
                                        rate=self.rate,
                                        input=True,
                                        frames_per_buffer=self.frames_per_buffer)
        for _ in range(int(self.rate / self.frames_per_buffer * duration)):
            audio = self._stream.read(self.frames_per_buffer)
            self.wavefile.writeframes(audio)
        return None

    def start_recording(self):
        # Use a stream with a callback in non-blocking mode
        self._stream = self._pa.open(format=pyaudio.paInt16,
                                        channels=self.channels,
                                        rate=self.rate,
                                        input=True,
                                        frames_per_buffer=self.frames_per_buffer,
                                        stream_callback=self.get_callback())
        self._stream.start_stream()
        return self

    def stop_recording(self):
        self._stream.stop_stream()
        return self

    def get_callback(self):
        def callback(in_data, frame_count, time_info, status):
            self.wavefile.writeframes(in_data)
            return in_data, pyaudio.paContinue
        return callback


    def close(self):
        self._stream.close()
        self._pa.terminate()
        self.wavefile.close()

    def _prepare_file(self, fname, mode='wb'):
        wavefile = wave.open(fname, mode)
        wavefile.setnchannels(self.channels)
        wavefile.setsampwidth(self._pa.get_sample_size(pyaudio.paInt16))
        wavefile.setframerate(self.rate)
        return wavefile


rec = Recorder(channels=1)
with rec.open('pipi.wav', 'wb') as recfile2:
    recfile2.start_recording()
    time.sleep(5.0)
    recfile2.stop_recording()


os.getcwd()















































def freq_to_note(freq):
    notes = ['A', 'A#', 'B', 'C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#']

    note_number = 12 * np.log2(freq / 440) + 49  
    note_number = round(note_number)
        
    note = (note_number - 1 ) % len(notes)
    note = notes[note]
    
    octave = (note_number + 8 ) // len(notes)
    
    return f"{note}_{octave}"


chunk = 2048 
sample_format = pyaudio.paInt16  
chanels = 1
sr = 44100 
seconds = 4


notes = []
times = []
p = pyaudio.PyAudio()  

stream = p.open(format=sample_format,
                 channels=chanels, 
                 rate=sr, input=True,
                 frames_per_buffer=chunk)
print('Recording...')
# Initialize array that be used for storing frames
frames = []  
 
# Store data in chunks for 8 seconds
# for i in range(0, int(sr / chunk * seconds)):
#     # amplitude = np.frombuffer(frames, np.int16)
#     # data = np.frombuffer(stream.read(chunk), np.int16)
#     # global notes, times
#     # time, frequency, _, _ = crepe.predict(data, 44100, viterbi=True)
#     # notes.extend(frequency)
#     # times.append(time)
#     frames.append(stream.read(chunk))
while True:
    global notes
    data = np.frombuffer(stream.read(chunk), np.int16)
    _, frequency, _, _ = crepe.predict(data, 44100, viterbi=True, verbose = 0)
    print([freq_to_note(x) for x in frequency])
    clear_output(wait=True)
    # frames.extend(frequency)


len(frames)


frames = b''.join(frames)
frames = np.frombuffer(frames, np.int16)
# Stop and close the stream 
stream.stop_stream()
stream.close()
 
# Terminate - PortAudio interface
p.terminate()


len(frames)











len(frames)


amplitude = frames


len(amplitude)


time, frequency, confidence, activation = crepe.predict(amplitude, 44100, viterbi=True)


frequency

















f = [freq_to_note(x) for x in frequency]


plt.plot(f)


















































chunk = 1024 
sample_format = pyaudio.paInt16  
chanels = 1
sr = 44100 
seconds = 4


pa = pyaudio.PyAudio()  

stream = pa.open(format=sample_format, channels=chanels, 
                 rate=sr, input=True, 
                 frames_per_buffer=chunk)
 
print('Recording...')
# Initialize array that be used for storing frames
frames = []  
 
# Store data in chunks for 8 seconds
for i in range(0, int(sr / chunk * seconds)):
    data = stream.read(chunk)
    frames.append(data)
frames = b''.join(frames)
# Stop and close the stream 
stream.stop_stream()
stream.close()
 
# Terminate - PortAudio interface
pa.terminate()


len(frames)


4/86


amplitude = np.frombuffer(frames, np.int16)


plt.plot(amplitude)


amplitude[:500]





time, frequency, confidence, activation = crepe.predict(amplitude[:1024], 44100, viterbi=True)











freq_to_note(141)


frequency


plt.plot(frequency)
# plt.ylim(100,140)



































audio_folder = "raw_data/raw_audio"
voices_folder = "raw_data/voices"


song_folder_url = "White_Copper_Alley___Lass_of_London_City_-_MÃ©nestrel"
song_voice_url = "vocals.wav"


song = os.path.join(voices_folder, song_folder_url, song_voice_url)





sr, audio = wavfile.read(song)


audio[350_000:350_050]








time, frequency, confidence, activation = crepe.predict(audio, sr, viterbi=True)


len(time)


len(frequency)


len(confidence)


len(activation)





time_split = time[2000:3000]
freq_split = frequency[2000:3000]


len(freq_split)


# Essentia is needed but only works in Linux
# ALthough it seems crepe is fine, maybe we'll never know
# [x if x<550 and x>180 else None for x in freq_split]


plt.figure(figsize=(10,6))
mean = np.mean(freq_split)
std = np.std(freq_split)
plt.scatter(time_split,[x if x<(mean+std) and x>(mean-std) else None for x in freq_split], alpha = 0.3)





np.std(freq_split)








len(time)


len(frequency)




















from spleeter.separator import Separator


separator = Separator(f"spleeter:2stems")
separator.separate_to_file(song,
                        "raw_data/voices",
                        duration = 540,
                        codec='wav',
                        filename_format='{filename}/{instrument}.{codec}')








one = videos_waiting_for_extract()[0]


one


import os
import ffmpeg
import string























# Sona_Is_A_Chill_Mom__Conan_O'Brien_Needs_A_Friend.m4a









































def callback(input_data, frame_count, time_info, flags):
    ...

    return input_data, pyaudio.paContinue

stream = audio.open(format=FORMAT,
                    channels=CHANNELS,
                    rate=RATE,
                    input=True,
                    stream_callback=callback,
                    frames_per_buffer=CHUNK)













































